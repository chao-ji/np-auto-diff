{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "iteration: 0, train accuracy: 0.120000, loss: 15.198036\n",
      "iteration: 50, train accuracy: 0.920000, loss: 0.372552\n",
      "iteration: 100, train accuracy: 0.920000, loss: 0.303580\n",
      "iteration: 150, train accuracy: 0.880000, loss: 0.378530\n",
      "iteration: 200, train accuracy: 0.960000, loss: 0.124584\n",
      "iteration: 250, train accuracy: 0.960000, loss: 0.241893\n",
      "iteration: 300, train accuracy: 0.920000, loss: 0.194320\n",
      "iteration: 350, train accuracy: 0.980000, loss: 0.158837\n",
      "iteration: 400, train accuracy: 0.960000, loss: 0.189886\n",
      "iteration: 450, train accuracy: 0.880000, loss: 0.310525\n",
      "accuracy = 0.9762\n"
     ]
    }
   ],
   "source": [
    "# Implement a simple ConvNet (Conv-Conv-FC-FC-READOUT) with dropout on the \n",
    "# second FC layer and optimized using Adam algorithm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from autodiff import *\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "batch = 50\n",
    "iterations = 500 \n",
    "\n",
    "sess = Session()\n",
    "\n",
    "X = PlaceholderOp((batch, 28, 28, 1), sess, False)\n",
    "Y_ = PlaceholderOp((batch, 10), sess, False)\n",
    "P = PlaceholderOp((), sess, False)\n",
    "W_CONV1 = PlaceholderOp((5, 5, 1, 32), sess)\n",
    "B_CONV1 = PlaceholderOp((32,), sess)\n",
    "W_CONV2 = PlaceholderOp((5, 5, 32, 64), sess)\n",
    "B_CONV2 = PlaceholderOp((64,), sess)\n",
    "W_FC1 = PlaceholderOp((7 * 7 * 64, 1024), sess)\n",
    "B_FC1 = PlaceholderOp((1024,), sess)\n",
    "W_FC2 = PlaceholderOp((1024, 10), sess)\n",
    "B_FC2 = PlaceholderOp((10,), sess)\n",
    "\n",
    "CONV1 = Conv2dOp(X, W_CONV1, [1, 1], \"SAME\", sess)\n",
    "CONV1_B = BiasAddOp(CONV1, B_CONV1, sess)\n",
    "H_CONV1 = ReluOp(CONV1_B, sess)\n",
    "H_POOL1 = MaxPool2dOp(H_CONV1, [2, 2], [2, 2], \"SAME\", sess)\n",
    "CONV2 = Conv2dOp(H_POOL1, W_CONV2, [1, 1], \"SAME\", sess)\n",
    "CONV2_B = BiasAddOp(CONV2, B_CONV2, sess)\n",
    "H_CONV2 = ReluOp(CONV2_B, sess)\n",
    "H_POOL2 = MaxPool2dOp(H_CONV2, [2, 2], [2, 2], \"SAME\", sess)\n",
    "H_POOL2_FLAT = ReshapeOp(H_POOL2, (batch, 7 * 7 * 64), sess)\n",
    "FC1 = MatMulOp(H_POOL2_FLAT, W_FC1, sess)\n",
    "FC1_B = BiasAddOp(FC1, B_FC1, sess)\n",
    "H_FC1 = ReluOp(FC1_B, sess)\n",
    "H_FC1_DROP = DropoutOp(H_FC1, P, sess)\n",
    "FC2 = MatMulOp(H_FC1_DROP, W_FC2, sess)\n",
    "Y_CONV = BiasAddOp(FC2, B_FC2, sess)\n",
    "SOFTMAX = SoftmaxCrossEntropyWithLogitsOp(Y_, Y_CONV, sess)\n",
    "CROSS_ENTROPY = ReduceMeanOp(SOFTMAX, 0, sess)\n",
    "\n",
    "w_conv1 = np.random.normal(scale=0.1, size=W_CONV1.shape)\n",
    "b_conv1 = np.ones(B_CONV1.shape) * 0.1\n",
    "w_conv2 = np.random.normal(scale=0.1, size=W_CONV2.shape)\n",
    "b_conv2 = np.ones(B_CONV2.shape) * 0.1\n",
    "w_fc1 = np.random.normal(scale=0.1, size=W_FC1.shape)\n",
    "b_fc1 = np.ones(B_FC1.shape) * 0.1\n",
    "w_fc2 = np.random.normal(scale=0.1, size=W_FC2.shape)\n",
    "b_fc2 = np.ones(B_FC2.shape) * 0.1\n",
    "\n",
    "feed_dict = { W_CONV1: w_conv1,\n",
    "              B_CONV1: b_conv1,\n",
    "              W_CONV2: w_conv2,\n",
    "              B_CONV2: b_conv2,\n",
    "              W_FC1: w_fc1,\n",
    "              B_FC1: b_fc1,\n",
    "              W_FC2: w_fc2,\n",
    "              B_FC2: b_fc2}\n",
    "\n",
    "params = {\"alpha\":  1e-3,\n",
    "          \"beta1\":  .9,\n",
    "          \"beta2\":  .999,\n",
    "          \"epsilon\":  1e-8,\n",
    "          \"t\":  0,\n",
    "          \"m\":  { W_CONV1: np.zeros_like(w_conv1),\n",
    "                  B_CONV1: np.zeros_like(b_conv1),\n",
    "                  W_CONV2: np.zeros_like(w_conv2),\n",
    "                  B_CONV2: np.zeros_like(b_conv2),\n",
    "                  W_FC1: np.zeros_like(w_fc1),\n",
    "                  B_FC1: np.zeros_like(b_fc1),\n",
    "                  W_FC2: np.zeros_like(w_fc2),\n",
    "                  B_FC2: np.zeros_like(b_fc2)},\n",
    "          \"v\":  { W_CONV1: np.zeros_like(w_conv1),\n",
    "                  B_CONV1: np.zeros_like(b_conv1),\n",
    "                  W_CONV2: np.zeros_like(w_conv2),\n",
    "                  B_CONV2: np.zeros_like(b_conv2),\n",
    "                  W_FC1: np.zeros_like(w_fc1),\n",
    "                  B_FC1: np.zeros_like(b_fc1),\n",
    "                  W_FC2: np.zeros_like(w_fc2),\n",
    "                  B_FC2: np.zeros_like(b_fc2)}}\n",
    "\n",
    "for i in range(iterations):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(batch)\n",
    "\n",
    "  feed_dict[X] = batch_xs.reshape((batch, 28, 28, 1))\n",
    "  feed_dict[Y_] = batch_ys\n",
    "  feed_dict[P] = .5\n",
    "\n",
    "  if i % 50 == 0:\n",
    "    Y_CONV_val = sess.eval_tensor(Y_CONV, feed_dict)\n",
    "    CROSS_ENTROPY_val = sess.eval_tensor(CROSS_ENTROPY, feed_dict)\n",
    "    print \"iteration: %d, train accuracy: %f, loss: %f\" % (i, np.mean(np.argmax(Y_CONV_val, axis=1) ==\n",
    "                                                                      np.argmax(batch_ys, axis=1)), \n",
    "                                                           CROSS_ENTROPY_val)\n",
    "\n",
    "  sess.adam_update(params, CROSS_ENTROPY, feed_dict)\n",
    "\n",
    "y_pred = np.array([])\n",
    "y_true = np.array([])\n",
    "for i in range(0, mnist.test.images.shape[0], batch):\n",
    "  feed_dict[X] = mnist.test.images[i : i + batch].reshape((batch, 28, 28, 1))\n",
    "  feed_dict[P] = 1.\n",
    "  Y_CONV_val = sess.eval_tensor(Y_CONV, feed_dict)\n",
    "  y_pred = np.append(y_pred, np.argmax(Y_CONV_val, axis=1))\n",
    "  y_true = np.append(y_true, np.argmax(mnist.test.labels[i : i + batch], axis=1))\n",
    "\n",
    "test_accuracy = np.mean(y_pred == y_true)\n",
    "print \"accuracy =\", test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
